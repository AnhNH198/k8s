---
# Source: neo4j/templates/service-account.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
    name: dev-neo4j-sa
---
# Source: neo4j/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: dev-neo4j-secrets
  labels:
    app.kubernetes.io/name: neo4j
    helm.sh/chart: "neo4j-4.2.5-1"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "dev"
type: Opaque
data:
  neo4j-password: "dHNnMTIzQDEyM2E="
---
# Source: neo4j/templates/common-configmap.yaml
# This ConfigMap gets passed to ALL CORE AND READ REPLICA cluster members to configure them.
# It contains the truly common things that are configuration wide.  The core and replica set
# each have a separate configmap for those concerns.
#
# Here we translate a lot of user settings & preferences into env vars that get passed
# to the Neo4j docker container.
apiVersion: v1
kind: ConfigMap
metadata:
  name: dev-neo4j-common-config
data:
  NEO4J_ACCEPT_LICENSE_AGREEMENT: "yes"
  NUMBER_OF_CORES: "3"
  AUTH_ENABLED: "true"
  # Enable listening for backups; default port 6362
  NEO4J_dbms_backup_enabled: "true"
  NEO4J_dbms_backup_listen__address: "0.0.0.0:6362"
  NEO4J_dbms_default__database: "neo4j"
  NEO4J_dbms_connector_bolt_listen__address: 0.0.0.0:7687
  NEO4J_dbms_connector_http_listen__address: 0.0.0.0:7474
  NEO4J_dbms_connector_https_listen__address: 0.0.0.0:7473
  NEO4J_causal__clustering_minimum__core__cluster__size__at__formation: "3"
  NEO4J_causal__clustering_minimum__core__cluster__size__at__runtime: "2"
  NEO4J_dbms_jvm_additional: "-XX:+ExitOnOutOfMemoryError"
  NEO4J_metrics_graphite_enabled: "false"
  NEO4J_metrics_graphite_server: "localhost:2003"
  NEO4J_metrics_graphite_interval: "3s"
  NEO4J_metrics_prometheus_enabled: "false"
  NEO4J_metrics_prometheus_endpoint: "localhost:2004"
  NEO4J_metrics_csv_enabled: "true"
  NEO4J_metrics_csv_interval: "3s"
  NEO4J_metrics_jmx_enabled: "true"
  NEO4JLABS_PLUGINS: "[\"apoc\"]"
  NEO4J_apoc_import_file_use__neo4j__config: "true"
---
# Source: neo4j/templates/core-configmap.yaml
# This ConfigMap gets passed to all core cluster members to configure them.
# Take note that some networking settings like internal hostname still get configured
# when the pod starts, but most non-networking specific configs can be tailored here.
apiVersion: v1
kind: ConfigMap
metadata:
  name: dev-neo4j-core-config
data:
  NEO4J_dbms_directories_logs: "/data/logs"
  # https://neo4j.com/docs/operations-manual/current/reference/configuration-settings/#config_dbms.mode
  NEO4J_dbms_mode: SINGLE
---
# Source: neo4j/templates/pod-init-script.yaml
# This is a bash script that runs on each pod when it starts up, and handles issues in the environment
# like configuration processing.
apiVersion: v1
kind: ConfigMap
metadata:
  name: "dev-init-script"
  labels:
    helm.sh/chart: neo4j-4.2.5-1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: "dev"
    app.kubernetes.io/name: neo4j
    app.kubernetes.io/component: init
data:
  init.sh: |-
    # Local hostname (graph-neo4j-core-0) converted to graph_neo4j_core_0
    # So that if a var is defined graph_neo4j_core_0_MYSETTING
    # its host-specific value will override whatever the default MYSETTING
    # is in the environment.
    # In this way we can give a single configmap to all 3 pods in a stateful
    # set, and still be able to do per-pod bespoke config.
    export override_prefix=$(hostname | sed s/-/_/g)
    # Ensure HOST is set, but take a default from the outer environment if present.
    export HOST=${HOST:-$(hostname -f)}

    declare -A NEO4J_SETTINGS

    # Populate NEO4J_SETTINGS with keys for all settings overriden as env vars
    for variable_name in $(compgen -e) ; do
      if [[ "${variable_name}" == "${override_prefix}"* ]]; then
        NEO4J_SETTINGS[${variable_name#"${override_prefix}_"}]=""
      fi
    done

    # HTTPS
    NEO4J_SETTINGS[dbms_connector_https_enabled]=true

    # Default settings values; either inherit from outward settings,
    # or, lacking any definition, take the local host 
    NEO4J_SETTINGS[NEO4J_dbms_default__advertised__address]=${NEO4J_dbms_default__advertised__address:-$HOST}
    NEO4J_SETTINGS[NEO4J_dbms_connector_bolt_advertised__address]=${NEO4J_dbms_connector_bolt_advertised__address:-$HOST:7687}
    NEO4J_SETTINGS[NEO4J_dbms_connector_http_advertised__address]=${NEO4J_dbms_connector_http_advertised__address:-$HOST:7474}
    NEO4J_SETTINGS[NEO4J_dbms_connector_https_advertised__address]=${NEO4J_dbms_connector_https_advertised__address:-$HOST:7473}
    NEO4J_SETTINGS[NEO4J_causal__clustering_discovery__advertised__address]=${NEO4J_causal__clustering_discovery__advertised__address:-$HOST:5000}

    # Important: note the label selector only does discovery against first 3 cores. This is intentional;
    # the list service API may return other hosts which aren't yet ready, and this will fail discovery
    # This setting is intentionally overridable for power users; discovery type of k8s is not.
    # See: https://github.com/neo4j-contrib/neo4j-helm/issues/80
    default_label_selector="neo4j.com/cluster=dev-neo4j,neo4j.com/role=CORE,neo4j.com/coreindex in (0, 1, 2)"
    NEO4J_SETTINGS[NEO4J_causal__clustering_kubernetes_label__selector]=${NEO4J_causal__clustering_kubernetes_label__selector:-$default_label_selector}

    neo4jAdminMemrec() {
      echo "Calling neo4j-admin memrec to suggest memory settings:"
      # Neo4j-admin memrec outputs configuration like this: dbms.memory.heap.max_size=9000m
      # with a lot of comments.  We strip the comments, then
      # process its output into a docker env var by following the Neo4j docker rules:
      # underscores doubled, dots -> _
      # So dbms.memory.heap.max_size=9000m => export NEO4J_dbms_memory_heap_max__size=9000m

      echo '' > /var/lib/neo4j/conf/memory-recommendations.sh
      for line in $( /var/lib/neo4j/bin/neo4j-admin memrec | grep -v '^\#' ) ; do
          # print out the memory recommendation that is being applied
          echo "${line}"
          echo "export $( echo "${line}" | sed 's/_/__/g' | sed 's/\./_/g' | sed 's/^/NEO4J_/g' )" >> /var/lib/neo4j/conf/memory-recommendations.sh
      done

      . /var/lib/neo4j/conf/memory-recommendations.sh
    }

    echo "Configuration override prefix = $override_prefix"

    # Check to see if a particular env var has a host-specific override.  If it does,
    # return the override.  Otherwise return the default value.
    getSettingValue() {
      # Setting key: $1
      # Default value: $2
      # Return: modify $SETTING_VALUE
      export override_varname=$override_prefix"_"$1
      # echo "Checking for override $override_varname"
      if [ -z "${!override_varname}" ] ; then
          SETTING_VALUE=$2
      else
          SETTING_VALUE=${!override_varname}
      fi
    }

    # For each config item, set an env var to the appropriate
    # metadata value or default value.  This sets us up for envsubst
    for setting in "${!NEO4J_SETTINGS[@]}" ; do
      # echo setting $setting
      # echo default 
      getSettingValue $setting "${NEO4J_SETTINGS[$setting]}"
      # echo "Setting $setting to $SETTING_VALUE"

      # Set the variable named setting to the result.
      # See: https://stackoverflow.com/questions/9714902/how-to-use-a-variables-value-as-another-variables-name-in-bash
      export $setting="$SETTING_VALUE"
    done

    if [ "${AUTH_ENABLED:-}" == "true" ]; then
      export NEO4J_AUTH="neo4j/${NEO4J_SECRETS_PASSWORD}"
    else
      export NEO4J_AUTH="none"
    fi

    # Once passed through to auth, unset this so Neo4j doesn't misinterpret it as config.
    unset NEO4J_SECRETS_PASSWORD
---
# Source: neo4j/templates/tests/test-script.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: "dev-test-script"
  labels:
    helm.sh/chart: neo4j-4.2.5-1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: "dev"
    app.kubernetes.io/name: neo4j
    app.kubernetes.io/component: tester
  annotations:
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
data:
  run.sh: |-
    export PATH=/usr/bin:$PATH
    export host="20.44.210.149"
    export replica_host="20.44.210.149"
    echo "HOST $host"
    # This endpoint proves availability of the overall service
    export endpoint="http://$host:$PORT_HTTP"
    echo "ENDPOINT $endpoint"
    # Mounted secret
    export NEO4J_SECRETS_PASSWORD=$(cat /secret/neo4j-password)
    export auth="neo4j:${NEO4J_SECRETS_PASSWORD}"
    echo "AUTH $auth"
    echo "CORES $CORES"
    echo "RRs $READ_REPLICAS"

    # When test resources are deployed cluster hasn't had a chance to form yet.
    # This polls in a loop waiting for cluster to become available, and gives up/fails
    # tests if it doesn't work within attempts.
    attempt=0
    attempts=5

    while true; do
      attempt=$[$attempt + 1]
      /usr/bin/curl -s -I $endpoint/ | grep "200 OK"
      if [ $? -eq 0 ] ; then
        echo "✔️ Neo4j is up at attempt $attempt; HTTP port $PORT_HTTP"
        break
      fi

      if [ $attempt -ge "$attempts" ]; then
        echo "❌ REST API seems not to be coming up, giving up after $attempts attempts"
        exit 1
      fi

      echo "Sleeping; not up yet after $attempt attempts"
      sleep 5
    done

    # Pass index ID to get hostname for that pod.
    function core_hostname {
      # Example: a-neo4j-core-0.a-neo4j.default.svc.cluster.local
      echo "dev-neo4j-core-$1.dev-neo4j.$NAMESPACE.svc.cluster.local"
    }

    function replica_hostname {      
      echo "dev-neo4j-replica-$1.dev-neo4j-replica.default.svc.cluster.local"
    }

    test_index=0

    function succeed {
      echo "✔️  Test $test_index: $1"
      test_index=$[$test_index + 1]
    }

    function fail {
      echo "❌ Test $test_index: $1"
      echo "Additional information: " "$2"
      exit 1
    }

    function cypher {
      # Use routing driver by default, send query wherever.
      DEFAULT_ENDPOINT="neo4j://$host:$PORT_BOLT"

      # If caller specified, use a specific endpoint to route a query to just one node.
      ENDPOINT=${2:-$DEFAULT_ENDPOINT}

      echo "$1" | /usr/bin/cypher-shell -u neo4j -a "$ENDPOINT" -p "$NEO4J_SECRETS_PASSWORD"
    }

    function runtest {
      # Use routing driver by default, send query wherever.
      DEFAULT_ENDPOINT="neo4j://$host:$PORT_BOLT"

      # If caller specified, use a specific endpoint to route a query to just one node.
      ENDPOINT=${3:-$DEFAULT_ENDPOINT}

      echo "Running $1 against $ENDPOINT"
      output=$(cypher "$2" "$3")

      if [ $? -eq 0 ] ; then  
        succeed "$1"
      else
        echo "Last output -- $output"
        fail "$1" "$output"
      fi
    }

    function check_secret_config_test {
       ENDPOINT=$1
       getconfig="call dbms.listConfig() yield name, value where name='dbms.transaction.concurrent.maximum' return value;"
       res=$(cypher "$getconfig" $ENDPOINT)

       echo $res | grep '"100"'
       if [ $? -eq 0 ] ; then
         succeed "$test"
       else
         fail "$test" "Expected it to be set to 0 - Output of config was $res"
       fi
    }

    # At this point the service endpoint proves that at least one host is up.
    # Provide just a bit more time for all of them to finish coming up because we'll
    # be testing them individually.
    echo "Waiting for formation to finish"
    attempt=0
    attempts=100
    while true; do
      attempt=$[$attempt + 1]
      cypher "RETURN 1;"
      if [ $? -eq 0 ] ; then
        echo "✔️ Neo4j BOLT is up at attempt $attempt; BOLT port $PORT_BOLT"
        break
      fi

      if [ $attempt -ge "$attempts" ]; then 
        echo "❌ BOLT API seems not to be coming up, giving up after $attempts attempts"
        exit 1
      fi

      echo "Sleeping; bolt not up yet after $attempt attempts"
      sleep 5
    done

    echo "All pre-requisites met, beginning main testing"

    echo "Basic topology upfront"
    cypher "CALL dbms.cluster.overview();"

    runtest "Bolt is available, port $PORT_BOLT"               "RETURN 'yes';"
    runtest "Basic read queries"                               "MATCH (n) RETURN COUNT(n);"
    runtest "Cluster accepts writes"                           'CREATE (t:TestNode) RETURN count(t);'

    # Clustering tests... # If database in clustered mode

    # Test for data replication.
    runtest "Sample canary write" 'CREATE (c:Canary) RETURN count(c);'
    echo "Sleeping a few seconds to permit replication"
    sleep 5

    echo "All good; testing completed"
    exit 0
---
# Source: neo4j/templates/service-account.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
    name: dev-neo4j-service-reader
rules:
    - apiGroups: [""] # "" indicates the core API group
      resources: ["services"]
      verbs: ["get", "watch", "list"]
---
# Source: neo4j/templates/service-account.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
    name: dev-neo4j-sa-to-service-reader-binding
subjects:
    - kind: ServiceAccount
      name: dev-neo4j-sa
roleRef:
    # "roleRef" specifies the binding to a Role / ClusterRole
    kind: Role # this must be Role or ClusterRole
    name: dev-neo4j-service-reader # this must match the name of the Role or ClusterRole you wish to bind to
    apiGroup: rbac.authorization.k8s.io
---
# Source: neo4j/templates/core-dns.yaml
# This service is intended for clients running in kubernetes to connect to the
# cluster.  This distinguishes it from discovery-lb which is about cluster formation
# and internal communication.
apiVersion: v1
kind: Service
metadata:
  name: dev-neo4j
  labels:
    neo4j.com/bolt: "true"
    neo4j.com/http: "true"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "dev"
    helm.sh/chart: "neo4j-4.2.5-1"
    app.kubernetes.io/name: neo4j
    app.kubernetes.io/component: core
spec:
  type: LoadBalancer
  loadBalancerIP: 20.44.210.149
  ports:
    - name: tcp-http
      port: 7474
      targetPort: 7474
    - name: tcp-bolt
      port: 7687
      targetPort: 7687
    - name: tcp-https
      port: 7473
      targetPort: 7473
    - name: tcp-backup
      port: 6362
      targetPort: 6362
  selector:
    app.kubernetes.io/name: neo4j
    app.kubernetes.io/instance: "dev"
    app.kubernetes.io/component: core
---
# Source: neo4j/templates/discovery-lb.yaml
apiVersion: v1
kind: Service
metadata:
  name: discovery-dev-neo4j-0
  labels:
    neo4j.com/coreindex: "0"
    neo4j.com/cluster: dev-neo4j
    neo4j.com/role: CORE
    neo4j.com/bolt: "false"
    neo4j.com/http: "false"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "dev"
    helm.sh/chart: "neo4j-4.2.5-1"
    app.kubernetes.io/name: neo4j
    app.kubernetes.io/component: core
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: tcp-discovery
      port: 5000
      targetPort: 5000
      protocol: TCP
    - name: tcp-transaction
      port: 6000
      targetPort: 6000
      protocol: TCP
    - name: tcp-raft
      port: 7000
      targetPort: 7000
      protocol: TCP
    - name: tcp-jmx
      port: 3637
      targetPort: 3637
      protocol: TCP
  selector:
    statefulset.kubernetes.io/pod-name: "dev-neo4j-core-0"
---
# Source: neo4j/templates/discovery-lb.yaml
apiVersion: v1
kind: Service
metadata:
  name: discovery-dev-neo4j-1
  labels:
    neo4j.com/coreindex: "1"
    neo4j.com/cluster: dev-neo4j
    neo4j.com/role: CORE
    neo4j.com/bolt: "false"
    neo4j.com/http: "false"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "dev"
    helm.sh/chart: "neo4j-4.2.5-1"
    app.kubernetes.io/name: neo4j
    app.kubernetes.io/component: core
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: tcp-discovery
      port: 5000
      targetPort: 5000
      protocol: TCP
    - name: tcp-transaction
      port: 6000
      targetPort: 6000
      protocol: TCP
    - name: tcp-raft
      port: 7000
      targetPort: 7000
      protocol: TCP
    - name: tcp-jmx
      port: 3637
      targetPort: 3637
      protocol: TCP
  selector:
    statefulset.kubernetes.io/pod-name: "dev-neo4j-core-1"
---
# Source: neo4j/templates/discovery-lb.yaml
apiVersion: v1
kind: Service
metadata:
  name: discovery-dev-neo4j-2
  labels:
    neo4j.com/coreindex: "2"
    neo4j.com/cluster: dev-neo4j
    neo4j.com/role: CORE
    neo4j.com/bolt: "false"
    neo4j.com/http: "false"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "dev"
    helm.sh/chart: "neo4j-4.2.5-1"
    app.kubernetes.io/name: neo4j
    app.kubernetes.io/component: core
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: tcp-discovery
      port: 5000
      targetPort: 5000
      protocol: TCP
    - name: tcp-transaction
      port: 6000
      targetPort: 6000
      protocol: TCP
    - name: tcp-raft
      port: 7000
      targetPort: 7000
      protocol: TCP
    - name: tcp-jmx
      port: 3637
      targetPort: 3637
      protocol: TCP
  selector:
    statefulset.kubernetes.io/pod-name: "dev-neo4j-core-2"
---
# Source: neo4j/templates/discovery-lb.yaml
apiVersion: v1
kind: Service
metadata:
  name: discovery-dev-neo4j-3
  labels:
    neo4j.com/coreindex: "3"
    neo4j.com/cluster: dev-neo4j
    neo4j.com/role: CORE
    neo4j.com/bolt: "false"
    neo4j.com/http: "false"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "dev"
    helm.sh/chart: "neo4j-4.2.5-1"
    app.kubernetes.io/name: neo4j
    app.kubernetes.io/component: core
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: tcp-discovery
      port: 5000
      targetPort: 5000
      protocol: TCP
    - name: tcp-transaction
      port: 6000
      targetPort: 6000
      protocol: TCP
    - name: tcp-raft
      port: 7000
      targetPort: 7000
      protocol: TCP
    - name: tcp-jmx
      port: 3637
      targetPort: 3637
      protocol: TCP
  selector:
    statefulset.kubernetes.io/pod-name: "dev-neo4j-core-3"
---
# Source: neo4j/templates/discovery-lb.yaml
apiVersion: v1
kind: Service
metadata:
  name: discovery-dev-neo4j-4
  labels:
    neo4j.com/coreindex: "4"
    neo4j.com/cluster: dev-neo4j
    neo4j.com/role: CORE
    neo4j.com/bolt: "false"
    neo4j.com/http: "false"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "dev"
    helm.sh/chart: "neo4j-4.2.5-1"
    app.kubernetes.io/name: neo4j
    app.kubernetes.io/component: core
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: tcp-discovery
      port: 5000
      targetPort: 5000
      protocol: TCP
    - name: tcp-transaction
      port: 6000
      targetPort: 6000
      protocol: TCP
    - name: tcp-raft
      port: 7000
      targetPort: 7000
      protocol: TCP
    - name: tcp-jmx
      port: 3637
      targetPort: 3637
      protocol: TCP
  selector:
    statefulset.kubernetes.io/pod-name: "dev-neo4j-core-4"
---
# Source: neo4j/templates/discovery-lb.yaml
apiVersion: v1
kind: Service
metadata:
  name: discovery-dev-neo4j-5
  labels:
    neo4j.com/coreindex: "5"
    neo4j.com/cluster: dev-neo4j
    neo4j.com/role: CORE
    neo4j.com/bolt: "false"
    neo4j.com/http: "false"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "dev"
    helm.sh/chart: "neo4j-4.2.5-1"
    app.kubernetes.io/name: neo4j
    app.kubernetes.io/component: core
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: tcp-discovery
      port: 5000
      targetPort: 5000
      protocol: TCP
    - name: tcp-transaction
      port: 6000
      targetPort: 6000
      protocol: TCP
    - name: tcp-raft
      port: 7000
      targetPort: 7000
      protocol: TCP
    - name: tcp-jmx
      port: 3637
      targetPort: 3637
      protocol: TCP
  selector:
    statefulset.kubernetes.io/pod-name: "dev-neo4j-core-5"
---
# Source: neo4j/templates/core-statefulset.yaml
apiVersion: "apps/v1"
kind: StatefulSet
metadata:
  name: "dev-neo4j-core"
  labels:
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "dev"
    helm.sh/chart: neo4j-4.2.5-1
    app.kubernetes.io/name: neo4j
    app.kubernetes.io/component: core
spec:
  podManagementPolicy: Parallel
  serviceName: dev-neo4j
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: "dev"
      app.kubernetes.io/name: neo4j
      app.kubernetes.io/component: core
  template:
    metadata:
      labels:
        app.kubernetes.io/managed-by: "Helm"
        app.kubernetes.io/instance: "dev"
        helm.sh/chart: "neo4j-4.2.5-1"
        app.kubernetes.io/name: neo4j
        app.kubernetes.io/component: core
    spec:
      serviceAccountName: dev-neo4j-sa
      automountServiceAccountToken: true
      # High value permits checkpointing on Neo4j shutdown.  See: https://neo4j.com/developer/kb/checkpointing-and-log-pruning-interactions/
      terminationGracePeriodSeconds: 300
      containers:
      - name: dev-neo4j
        image: "neo4j:4.2.5-enterprise"
        imagePullPolicy: "IfNotPresent"
        envFrom:
          - configMapRef:
              name: dev-neo4j-common-config
          - configMapRef:
              name: dev-neo4j-core-config
        env:
          - name: NEO4J_SECRETS_PASSWORD
            valueFrom:
              secretKeyRef:
                name: dev-neo4j-secrets
                key: neo4j-password
        command:
          - "/bin/bash"
          - "-c"
          - |
            export core_idx=$(hostname | sed 's|.*-||')

            # Processes key configuration elements and exports env vars we need.
            . /helm-init/init.sh

            echo "Starting Neo4j CORE $core_idx on $HOST"
            exec /docker-entrypoint.sh "neo4j"
        ports:
        - containerPort: 5000
          name: tcp-discovery
        - containerPort: 7000
          name: tcp-raft
        - containerPort: 6000
          name: tcp-tx
        - containerPort: 7474
          name: tcp-browser
        - containerPort: 7687
          name: tcp-bolt
        - containerPort: 7688
          name: tcp-boltrouting
        - containerPort: 3637
          name: tcp-jmx
        volumeMounts:
        - name: init-script
          mountPath: /helm-init
        - name: datadir
          mountPath: "/data"
        - name: plugins
          mountPath: /plugins
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 120
          periodSeconds: 10
          tcpSocket:
            port: 7687
          timeoutSeconds: 2
        livenessProbe:
          failureThreshold: 3
          initialDelaySeconds: 300
          periodSeconds: 10
          tcpSocket:
            port: 7687
          timeoutSeconds: 2
        resources:
          {}
      initContainers:
      
      securityContext:
        {}
      volumes:
        - name: init-script
          configMap:
            name: "dev-init-script"
        - name: plugins
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: datadir
        annotations:
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: "10Gi"
---
# Source: neo4j/templates/discovery-lb.yaml
# This creates a discovery Service for each member in the core set, and ties to
# the use of the Neo4j discovery type "K8S" with the configured selectors.
# Done as many times as there are core machines, or just once if standalone.
#
# IMPORTANT - related to scaling, in order for the cluster to form correctly
# there must be one of these per core node.  As a result, we intentionally create
# too many of them in the causal cluster scenario to ensure that when pods scale
# up, there are extra discovery addresses to cover them.
##########################################################################
---
# Source: neo4j/templates/readreplicas-statefulset.yaml
# if not standalone mode
---
# Source: neo4j/templates/tests/tester.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "dev-neo4j-service-test-i21xf"
  labels:
    helm.sh/chart: neo4j-4.2.5-1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: "dev"
    app.kubernetes.io/name: neo4j
    app.kubernetes.io/component: tester
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-delete-policy": "before-hook-creation"
spec:
  containers:
  - name: dev-ui-test
    image: gcr.io/neo4j-helm/tester:4.2.5-1
    imagePullPolicy: IfNotPresent
    env:
      - name: NAME
        value: "dev"
      - name: CORES
        value: "3"
      - name: READ_REPLICAS
        value: "0"
      - name: NAMESPACE
        value: "default"
      - name: PORT_HTTP
        value: "7474"
      - name: PORT_BOLT
        value: "7687"
    volumeMounts:
      - name: secret-volume
        mountPath: /secret
        readOnly: true
      - name: config-volume
        mountPath: /tester
        readOnly: true
    command: ["/bin/bash"]
    args: ["/tester/run.sh"]
  restartPolicy: Never
  volumes:
    - name: secret-volume
      secret:
        secretName: dev-neo4j-secrets
        items:
          - key: neo4j-password
            path: neo4j-password
    - name: config-volume
      configMap:
        name: "dev-test-script"
